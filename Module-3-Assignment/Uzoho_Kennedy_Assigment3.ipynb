{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 1.7258 - accuracy: 0.3923 - val_loss: 1.3618 - val_accuracy: 0.5252\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 1.3592 - accuracy: 0.5196 - val_loss: 1.6176 - val_accuracy: 0.4412\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 1.2355 - accuracy: 0.5644 - val_loss: 1.1881 - val_accuracy: 0.5852\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 1.1444 - accuracy: 0.5987 - val_loss: 1.2097 - val_accuracy: 0.5846\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 1.0712 - accuracy: 0.6242 - val_loss: 1.1338 - val_accuracy: 0.6059\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 1.0160 - accuracy: 0.6440 - val_loss: 1.0588 - val_accuracy: 0.6329\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.9586 - accuracy: 0.6631 - val_loss: 1.0194 - val_accuracy: 0.6572\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.9164 - accuracy: 0.6792 - val_loss: 1.0820 - val_accuracy: 0.6347\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.8671 - accuracy: 0.6977 - val_loss: 1.1769 - val_accuracy: 0.6183\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.8303 - accuracy: 0.7119 - val_loss: 1.0155 - val_accuracy: 0.6601\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.7933 - accuracy: 0.7225 - val_loss: 1.0048 - val_accuracy: 0.6670\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.7618 - accuracy: 0.7346 - val_loss: 1.0006 - val_accuracy: 0.6649\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.7350 - accuracy: 0.7463 - val_loss: 0.9921 - val_accuracy: 0.6731\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.7032 - accuracy: 0.7581 - val_loss: 1.1387 - val_accuracy: 0.6415\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.6764 - accuracy: 0.7674 - val_loss: 1.0023 - val_accuracy: 0.6765\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.6554 - accuracy: 0.7754 - val_loss: 1.0463 - val_accuracy: 0.6747\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.6349 - accuracy: 0.7800 - val_loss: 0.9853 - val_accuracy: 0.6810\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.6127 - accuracy: 0.7893 - val_loss: 1.0658 - val_accuracy: 0.6718\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.5947 - accuracy: 0.7958 - val_loss: 1.0537 - val_accuracy: 0.6896\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.5740 - accuracy: 0.8021 - val_loss: 1.1193 - val_accuracy: 0.6639\n",
      "10000/10000 [==============================] - 5s 485us/step\n",
      "Test score: 1.117372644996643\n",
      "Test accuracy: 0.6524999737739563\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,842\n",
      "Trainable params: 1,676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 95s 2ms/step - loss: 1.8139 - accuracy: 0.3470 - val_loss: 1.4869 - val_accuracy: 0.4683\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 1.3494 - accuracy: 0.5181 - val_loss: 1.3006 - val_accuracy: 0.5434\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 1.1290 - accuracy: 0.6022 - val_loss: 1.1552 - val_accuracy: 0.5862\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 93s 2ms/step - loss: 0.9897 - accuracy: 0.6532 - val_loss: 0.9308 - val_accuracy: 0.6768\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.9015 - accuracy: 0.6859 - val_loss: 0.9150 - val_accuracy: 0.6767\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.8257 - accuracy: 0.7120 - val_loss: 0.8725 - val_accuracy: 0.7037\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 102s 3ms/step - loss: 0.7691 - accuracy: 0.7330 - val_loss: 0.8324 - val_accuracy: 0.7172\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.7217 - accuracy: 0.7471 - val_loss: 0.7943 - val_accuracy: 0.7301\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.6800 - accuracy: 0.7628 - val_loss: 0.7276 - val_accuracy: 0.7539\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.6450 - accuracy: 0.7774 - val_loss: 0.7548 - val_accuracy: 0.7475\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.6230 - accuracy: 0.7847 - val_loss: 0.6907 - val_accuracy: 0.7699\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.6066 - accuracy: 0.7917 - val_loss: 0.7521 - val_accuracy: 0.7609\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.5927 - accuracy: 0.7972 - val_loss: 0.6766 - val_accuracy: 0.7762\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.5749 - accuracy: 0.8061 - val_loss: 0.7087 - val_accuracy: 0.7709\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.5688 - accuracy: 0.8092 - val_loss: 0.7703 - val_accuracy: 0.7682\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.5685 - accuracy: 0.8112 - val_loss: 0.8416 - val_accuracy: 0.7319\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.5593 - accuracy: 0.8099 - val_loss: 0.7900 - val_accuracy: 0.7780\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.5580 - accuracy: 0.8117 - val_loss: 0.8005 - val_accuracy: 0.7796\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.5467 - accuracy: 0.8182 - val_loss: 0.7463 - val_accuracy: 0.7780\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.5543 - accuracy: 0.8169 - val_loss: 0.8944 - val_accuracy: 0.7414\n",
      "10000/10000 [==============================] - 9s 892us/step\n",
      "Test score: 0.9256065427780151\n",
      "Test accuracy: 0.7332000136375427\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,842\n",
      "Trainable params: 1,676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Deeper network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm could result in ethical and privacy concerns if it were trained on different sets of images.\n",
    "\n",
    "One concern is that if the model is trained on biased data, it can perpetuate and even amplify these biases in its predictions. For example, if the dataset used to train the model contains mostly images of light-skinned people, the model may not be able to accurately recognize or classify images of people with darker skin tones. This can have serious consequences, particularly in applications such as facial recognition or criminal justice, where a lack of diversity in the training data can lead to discrimination against marginalized groups.\n",
    "\n",
    "Another concern is that the model may be used to make predictions about individuals without their consent or knowledge, potentially leading to privacy violations. For example, if the model is trained on images of people's faces and is used to make predictions about their identities or other personal information, this could be a violation of their privacy rights.\n",
    "\n",
    "Additionally, if the data used to train the model is not properly anonymized, it could be possible to re-identify individuals in the dataset, potentially compromising their privacy.\n",
    "\n",
    "It is important for the creators and users of machine learning models like this one to be aware of these ethical and privacy concerns and to take steps to mitigate them, such as using diverse and representative training data, obtaining informed consent from individuals whose data is used, and properly anonymizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
